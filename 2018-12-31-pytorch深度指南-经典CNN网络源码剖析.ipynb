{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"pytorch深度指南-经典CNN网络源码剖析\"\n",
    "date:   2018-12-31 23:14:58 +0800\n",
    "categories: jekyll update\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 经典CNN\n",
    "常用来做为主干网络，也就是paper中常常提到的backbone，用于实现分类或提取特征  \n",
    "pytroch给出了经典网络的搭建代码，放在`torchvision.models`中，官方封装好了类接口，可以直接调用  \n",
    ">此文不仅仅关注网络结构特性理解，更关注**如何使用pytorch搭建网络结构**  \n",
    "可以结合之前的博客[pytorch深度指南-网络模型搭建与源码剖析](http://)，理解pytorch网络设计模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG\n",
    "### 简单介绍\n",
    "VGG网络是在AlexNet网络的基础上发展而来的，其主要贡献在于使用非常小的3*3的卷积核进行网络设计，并且将网络深度增加到16-19层。在2014年ImageNet比赛中，获得了定位第1，分类第2的好成绩，网络具有很好的泛化能力。\n",
    "\n",
    "### Notice:\n",
    "* 全部conv均使用了3×3的卷积核\n",
    "* 一共使用了5次maxpooling，也就意味着$out_{resolution} = input_{resolution} / 2^5$\n",
    "![vgg_config](/img/vgg_config.png)\n",
    "* 最后有三个全连接层(nn.Linear)，因此VGG参数量巨大\n",
    "* 因为用到了FC，输入tensor的H和W需要固定(3×224×224)\n",
    "### 代码剖析\n",
    "下面以常用的VGG16为例讲解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):#ImageNet训练共1000类\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features#提取特征部分，也就是CNN部分\n",
    "        self.classifier = nn.Sequential(#分类部分，也就是全连接层部分\n",
    "            nn.Linear(512 * 7 * 7, 4096),#参数量512*7*7*4096=102,760,448\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),#参数量4096*4096=16,777,216\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),#参数量4096*1000=4,096,000\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)#经过之前CNN输出的尺寸为(512cx7hx7w)\n",
    "        x = x.view(x.size(0), -1)#为了送入FC层，需要将tensor展平\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):#网络权重初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):#如果是卷积层\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))#使用normal初始化\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()#对bias全部0填充\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "cfg = {#VGG论文表格中的网络结构config(上图)，ABDE表示中四种不同深度的网络，'M'表示maxpooling\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):#创建重复的网络模块\n",
    "    layers = []\n",
    "    in_channels = 3#输入通道数\n",
    "    for v in cfg:#从图纸cfg读入网络结构信息，判断该添加哪个模块\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:#使用list创建一个序列，根据情况是否使用BN层\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v#输入通道迭代更新\n",
    "    return nn.Sequential(*layers)#使用nn.Sequential(*list)创建一个串行Conv序列\n",
    "\n",
    "def vgg16(pretrained=False, **kwargs):#VGG16使用了cfg['D']结构\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\")\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:#是否使用预训练模型，\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['D']), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))#加载预训练网络参数\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**打个总结：**\n",
    "* 确定网络基模块，利用图纸化(cfg)搭建复杂网络结构  \n",
    "* 使用`nn.Sequential()`打造多个重复基模块\n",
    "* 如果使用FC层，需要确定输入输出节点数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "### 简单介绍\n",
    "Kaiming大神的代表作之一，被广泛应用于各种网络作为backbone，引入了残差概念解决梯度消失问题，使网络深度大幅度增加成为了可能。\n",
    "\n",
    "### Notice:\n",
    "* `in_planes, out_planes` 即输入输出通道的数量，从Resnet之后，网络都是以模块化搭建。Resnet包含两种基本模块:\n",
    "* **residual**残差使用的是**pixel-wise**相加  \n",
    "* **基本模块:**\n",
    " * BasicBlock(左，Resnet-34及以下使用的模块)\n",
    " * BottleNeck(右，Resnet-50及以上使用1x1conv进行通道缩放，从而减少3x3conv的参数量)\n",
    "![resnet-basicblock](/img/basicblock.png)\n",
    "这两种网络在论文中都有详细介绍。其中浅层ReseNet-34层用了BasicBlock，深层的50及以上使用了BottleNeck  \n",
    "* 无论哪个深度，Resnet一共包含5个stage，第一个stage使用了7×7的conv，紧跟着maxpooling\n",
    "* Resnet-50和Resnet-34使用的都是[3,4,6,3]重复模式，每经过一个阶段，resolution/2,channel*2\n",
    "![resnet_](/img/resnet_cfg.png)\n",
    "* Resnet 在stage2-5均没有用maxpooling进行resolution变化，使用stride=2进行downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "Resnet不同stage连接处会出现通道和分辨率不匹配的问题，为了完成尺度匹配，使用带有Projection的Block，即使用downsample的BasicBlock。  \n",
    "[resnet-projection](/img/resnet_projection.jpg)\n",
    ">The projection shortcut in Eqn2. is used to match dimensions (done by 1x1 conv). For both options, when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2.(Resnet原文介绍Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):#基本的3x3卷积\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "class BasicBlock(nn.Module):#BasicBlock模块\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x#保留输入作为残差\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:#在downsample网络使用stride=2的降分辨率作为残差\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual#经过conv后与之前的input相加\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):#Bottleneck模块\n",
    "    expansion = 4#注意，bottleneck要对输入通道做4倍拉升，用到expansion\n",
    "\n",
    "    def __init__(self, , stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)#此处改为planes * Bottleneck.expansion会不会好一点？\n",
    "        #最后的conv的channel是输入的4倍\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample#downsample即stride=2的层\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:#在downsample网络使用stride=2的降分辨率作为残差\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)#注意开始的conv1使用了K=7,S=2\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)#Stage1中唯一出现了一次Maxpooling\n",
    "        #C2-C5输入通道数量[64,128,256,512]\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])#注意:layer1的stride=1!\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)#使用了Global Average Pooling\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):#同样使用了_make_layer的方式造基模块轮子\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:#只有在stage节点交汇处才会downsample\n",
    "            downsample = nn.Sequential(#downsample表示在不同stage的节点连接处降分辨率同时提升通道数\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,#使用1x1升通道降分辨\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))#每个stage的第一个block可能会有downsample，\n",
    "        self.inplanes = planes * block.expansion#迭代更新inplanes=planes*4，为下一层输入的通道数量\n",
    "        for i in range(1, blocks):#剩余的block都是同样的搞法\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)#尺度变化从而送入后面的全连接层\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def resnet50(pretrained=False, **kwargs):#Resnet API调用接口\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)#[3,4,6,3]为各个stage中block重复次数\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception\n",
    "### 简单介绍\n",
    "### 代码剖析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v3(pretrained=False, **kwargs):\n",
    "    r\"\"\"Inception v3 model architecture from\n",
    "    `\"Rethinking the Inception Architecture for Computer Vision\" <http://arxiv.org/abs/1512.00567>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        if 'transform_input' not in kwargs:\n",
    "            kwargs['transform_input'] = True\n",
    "        model = Inception3(**kwargs)\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['inception_v3_google']))\n",
    "        return model\n",
    "\n",
    "    return Inception3(**kwargs)\n",
    "\n",
    "\n",
    "class Inception3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000, aux_logits=True, transform_input=False):\n",
    "        super(Inception3, self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "        self.Conv2d_1a_3x3 = BasicConv2d(3, 32, kernel_size=3, stride=2)\n",
    "        self.Conv2d_2a_3x3 = BasicConv2d(32, 32, kernel_size=3)\n",
    "        self.Conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.Conv2d_3b_1x1 = BasicConv2d(64, 80, kernel_size=1)\n",
    "        self.Conv2d_4a_3x3 = BasicConv2d(80, 192, kernel_size=3)\n",
    "        self.Mixed_5b = InceptionA(192, pool_features=32)\n",
    "        self.Mixed_5c = InceptionA(256, pool_features=64)\n",
    "        self.Mixed_5d = InceptionA(288, pool_features=64)\n",
    "        self.Mixed_6a = InceptionB(288)\n",
    "        self.Mixed_6b = InceptionC(768, channels_7x7=128)\n",
    "        self.Mixed_6c = InceptionC(768, channels_7x7=160)\n",
    "        self.Mixed_6d = InceptionC(768, channels_7x7=160)\n",
    "        self.Mixed_6e = InceptionC(768, channels_7x7=192)\n",
    "        if aux_logits:\n",
    "            self.AuxLogits = InceptionAux(768, num_classes)\n",
    "        self.Mixed_7a = InceptionD(768)\n",
    "        self.Mixed_7b = InceptionE(1280)\n",
    "        self.Mixed_7c = InceptionE(2048)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                import scipy.stats as stats\n",
    "                stddev = m.stddev if hasattr(m, 'stddev') else 0.1\n",
    "                X = stats.truncnorm(-2, 2, scale=stddev)\n",
    "                values = torch.Tensor(X.rvs(m.weight.data.numel()))\n",
    "                values = values.view(m.weight.data.size())\n",
    "                m.weight.data.copy_(values)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.transform_input:\n",
    "            x = x.clone()\n",
    "            x[:, 0] = x[:, 0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x[:, 1] = x[:, 1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x[:, 2] = x[:, 2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "        # 299 x 299 x 3\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # 149 x 149 x 32\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # 147 x 147 x 32\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # 147 x 147 x 64\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        # 73 x 73 x 64\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # 73 x 73 x 80\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # 71 x 71 x 192\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        # 35 x 35 x 192\n",
    "        x = self.Mixed_5b(x)\n",
    "        # 35 x 35 x 256\n",
    "        x = self.Mixed_5c(x)\n",
    "        # 35 x 35 x 288\n",
    "        x = self.Mixed_5d(x)\n",
    "        # 35 x 35 x 288\n",
    "        x = self.Mixed_6a(x)\n",
    "        # 17 x 17 x 768\n",
    "        x = self.Mixed_6b(x)\n",
    "        # 17 x 17 x 768\n",
    "        x = self.Mixed_6c(x)\n",
    "        # 17 x 17 x 768\n",
    "        x = self.Mixed_6d(x)\n",
    "        # 17 x 17 x 768\n",
    "        x = self.Mixed_6e(x)\n",
    "        # 17 x 17 x 768\n",
    "        if self.training and self.aux_logits:\n",
    "            aux = self.AuxLogits(x)\n",
    "        # 17 x 17 x 768\n",
    "        x = self.Mixed_7a(x)\n",
    "        # 8 x 8 x 1280\n",
    "        x = self.Mixed_7b(x)\n",
    "        # 8 x 8 x 2048\n",
    "        x = self.Mixed_7c(x)\n",
    "        # 8 x 8 x 2048\n",
    "        x = F.avg_pool2d(x, kernel_size=8)\n",
    "        # 1 x 1 x 2048\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # 1 x 1 x 2048\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # 2048\n",
    "        x = self.fc(x)\n",
    "        # 1000 (num_classes)\n",
    "        if self.training and self.aux_logits:\n",
    "            return x, aux\n",
    "        return x\n",
    "\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = BasicConv2d(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionB, self).__init__()\n",
    "        self.branch3x3 = BasicConv2d(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, channels_7x7):\n",
    "        super(InceptionC, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        c7 = channels_7x7\n",
    "        self.branch7x7_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7_2 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = BasicConv2d(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "\n",
    "        self.branch7x7dbl_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7dbl_2 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_3 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7dbl_4 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_5 = BasicConv2d(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionD(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionD, self).__init__()\n",
    "        self.branch3x3_1 = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "        self.branch3x3_2 = BasicConv2d(192, 320, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch7x7x3_1 = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "        self.branch7x7x3_2 = BasicConv2d(192, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7x3_3 = BasicConv2d(192, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7x3_4 = BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_1(x)\n",
    "        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        outputs = [branch3x3, branch7x7x3, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionE, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 320, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = BasicConv2d(in_channels, 384, kernel_size=1)\n",
    "        self.branch3x3_2a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 448, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(448, 384, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3),\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(InceptionAux, self).__init__()\n",
    "        self.conv0 = BasicConv2d(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = BasicConv2d(128, 768, kernel_size=5)\n",
    "        self.conv1.stddev = 0.01\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        self.fc.stddev = 0.001\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 17 x 17 x 768\n",
    "        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n",
    "        # 5 x 5 x 768\n",
    "        x = self.conv0(x)\n",
    "        # 5 x 5 x 128\n",
    "        x = self.conv1(x)\n",
    "        # 1 x 1 x 768\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # 768\n",
    "        x = self.fc(x)\n",
    "        # 1000\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
