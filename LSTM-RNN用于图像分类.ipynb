{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN用于图像分类\n",
    "RNN 一般是用做时间序列的数据，在这里，也可以将图像数据看成时间序列的，将每行像素看做输入的数据\n",
    "对于minist数据集，训练图片为手写数字图片，标签为相应的整型数字,需要注意的是，使用crossEntropy进行分类的时候，函数会自动将标签对应的数字标签转换为onehot形式进行处理\n",
    "## Appeals\n",
    "One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task<br/>\n",
    "## Features\n",
    "the key to LSTMS is the cell state. The cell state is kind of like a conveyor belt. It runs straght down the entire chain, with only some minor linear interactions. It's very easy for information to just flow along it unchanged. The LSTM dows have the ability to remove or add information to the cell state, carefully regulated by structures called gates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH=1\n",
    "BATCH_SIZE=64\n",
    "TIME_STEP=28\n",
    "INPUT_SIZE=28\n",
    "LR=0.01\n",
    "DOWNLOAD_MNIST=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=dsets.MNIST(root='./mnist',train=True,transform=transforms.ToTensor(),download=False)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data=dsets.MNIST(root='./mnist',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x=test_data.test_data[:2000].type(torch.FloatTensor)/255\n",
    "test_y=test_data.test_labels[:2000].type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init___(self):\n",
    "        super(RNN,self).__init__()\n",
    "        self.rnn=nn.LSTM(input_size=INPUT_SIZE,\n",
    "                        hidden_size=64,\n",
    "                        num_layers=1,\n",
    "                        batch_first=True,)\n",
    "        self.out=nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        r_out,(h_n,h_c)=self.rnn(x,None)\n",
    "        out=self.out(r_out[:,-1,:])#(batch,time_step,input)\n",
    "        return out\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.rnn=nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out=nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn=RNN()\n",
    "print(rnn,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type uint8_t without overflow: 2000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-796f4eaac95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpred_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'|train loss:%.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'| test accuracy:%.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: value cannot be converted to type uint8_t without overflow: 2000"
     ]
    }
   ],
   "source": [
    "optimizer=torch.optim.Adam(rnn.parameters(),lr=LR)\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        b_x=x.view(-1,28,28)\n",
    "        b_y=y\n",
    "        output=rnn(b_x)\n",
    "        loss=loss_func(output,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step%50==0:\n",
    "            test_output=rnn(test_x)\n",
    "            pred_y=torch.max(test_output,1)[1].data.numpy().squeeze()\n",
    "            print (test_y.size()[0])\n",
    "            accuracy=sum(pred_y==test_y)/test_y.size()[0]\n",
    "            print ('Epoch:',epoch,'|train loss:%.4f'%loss.data[0],'| test accuracy:%.4f'%accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
